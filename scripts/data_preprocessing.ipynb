{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the below according the directories of new folder location and current bagls location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagls = r\"D:\\FYP Datasets\\BAGLS\" #to change to the path of the BAGLS dataset\n",
    "output = r\"D:\\FYP Datasets\\fyp\" #to change to the path of the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagls_test_t = os.path.join(bagls, \"test\", \"test\")\n",
    "# bagls_test_a = os.path.join(bagls, \"test\", \"annotations\") #if bbox is done\n",
    "bagls_train_t = os.path.join(bagls, \"training\", \"training\")\n",
    "# bagls_train_a = os.path.join(bagls, \"training\", \"annotations\") #if bbox is done\n",
    "\n",
    "o_images = os.path.join(output, \"raw\", \"images\")\n",
    "o_labels = os.path.join(output, \"raw\", \"labels\")\n",
    "\n",
    "#create the directory for the output folder\n",
    "os.makedirs(o_images, exist_ok=True)\n",
    "os.makedirs(o_labels, exist_ok=True)\n",
    "\n",
    "#for training \n",
    "train_img = os.path.join(output, \"training\", \"train\", \"images\")\n",
    "train_label = os.path.join(output, \"training\", \"train\", \"labels\")\n",
    "val_img = os.path.join(output, \"training\", \"val\", \"images\")\n",
    "val_label = os.path.join(output, \"training\", \"val\", \"labels\")\n",
    "test_img = os.path.join(output, \"training\", \"test\", \"images\")\n",
    "test_label = os.path.join(output, \"training\", \"test\", \"labels\")\n",
    "\n",
    "os.makedirs(train_img, exist_ok=True)\n",
    "os.makedirs(train_label, exist_ok=True)\n",
    "os.makedirs(val_img, exist_ok=True)\n",
    "os.makedirs(val_label, exist_ok=True)\n",
    "os.makedirs(test_img, exist_ok=True)\n",
    "os.makedirs(test_label, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy over data files from bagls to output folder ##\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done with training data first followed by test data.\n",
    "For test data, everything will be renamed starting from the last index of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying train images and annotations\n",
    "for filename in os.listdir(bagls_train_t):\n",
    "    shutil.copy2(os.path.join(bagls_train_t, filename), o_images)\n",
    "\n",
    "#if bbox is done\n",
    "# for filename in os.listdir(bagls_train_a):\n",
    "#     shutil.copy2(os.path.join(bagls_train_a, filename), o_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastnum = 0\n",
    "checker = 0\n",
    "for file in os.listdir(o_images):\n",
    "    if file.endswith(\".png\"):\n",
    "        lastnum += 1\n",
    "\n",
    "#if bbox is done    \n",
    "# for file in os.listdir(o_labels):\n",
    "#     if file.endswith(\".txt\"):\n",
    "#         checker += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying test images and annotations and rename starting from the last number\n",
    "counter1,counter2,counter3 = lastnum, lastnum, lastnum\n",
    "for filename in os.listdir(bagls_test_t):\n",
    "    if filename.endswith(\"_seg.png\"):\n",
    "        shutil.copy2(os.path.join(bagls_test_t, filename), os.path.join(o_images, str(counter1)+\"_seg.png\"))\n",
    "        counter1 += 1\n",
    "    elif filename.endswith(\".meta\"):\n",
    "        shutil.copy2(os.path.join(bagls_test_t, filename), os.path.join(o_images, str(counter2)+\".meta\"))\n",
    "        counter2 += 1\n",
    "    elif filename.endswith(\".png\") and not filename.endswith(\"_seg.png\"):\n",
    "        shutil.copy2(os.path.join(bagls_test_t, filename), os.path.join(o_images, str(counter3)+\".png\"))\n",
    "        counter3 += 1\n",
    "        \n",
    "#only if bbox is done\n",
    "# for filename in os.listdir(bagls_test_a):\n",
    "#     f = int(filename.split(\".\")[0])\n",
    "#     shutil.copy2(os.path.join(bagls_test_a, filename), os.path.join(o_labels, str(f+lastnum)+\".txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images:  59250\n"
     ]
    }
   ],
   "source": [
    "#checker for the number of images and labels\n",
    "print(\"Number of images: \", len(os.listdir(o_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finds bounding boxes all iamges and creates an label file in the images folder #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only done for bagls dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_bounding_boxes(img):\n",
    "    x_min, y_min, x_max, y_max = float('inf'), float('inf'), 0, 0\n",
    "    cntrs, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in cntrs:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        x_min = min(x_min, x)\n",
    "        y_min = min(y_min, y)\n",
    "        x_max = max(x_max, x + w)\n",
    "        y_max = max(y_max, y + h)\n",
    "    #convert to yolo\n",
    "    x_center = (x_min + x_max) / 2 / img.shape[1]\n",
    "    y_center = (y_min + y_max) / 2 / img.shape[0]\n",
    "    width = (x_max - x_min) / img.shape[1]\n",
    "    height = (y_max - y_min) / img.shape[0]\n",
    "    return x_center, y_center, width, height\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(o_images):\n",
    "    if file.endswith(\"_seg.png\"):\n",
    "        img = cv2.imread(os.path.join(o_images, file), cv2.IMREAD_GRAYSCALE)\n",
    "        x, y, w, h = detect_bounding_boxes(img)\n",
    "        if x == float('inf') or y == float('inf'):\n",
    "            continue\n",
    "        #write in a new text file and save in another folder\n",
    "        with open(os.path.join(o_labels, file.replace(\"_seg.png\", \".txt\")), \"w\") as f: #replace _seg.png with .txt to follow \n",
    "            f.write(f\"3 {x} {y} {w} {h}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected labels from BAGLS is 55,286\n",
      "Number of labels:  59250\n"
     ]
    }
   ],
   "source": [
    "#checker\n",
    "print(\"Expected labels from BAGLS is 55,286\")\n",
    "print(\"Number of labels: \", len(os.listdir(o_labels))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating metadata file for the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*needs to be done before adding negative samples*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_file = os.path.join(o_images, \"0.meta\")\n",
    "with open(meta_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    headers = data.keys()\n",
    "    headers = list(headers)\n",
    "    headers.append('glottis status')\n",
    "    headers.append('Type')\n",
    "    headers.insert(0, 'Filename')\n",
    "    with open(output + \"/metadata.csv\" , 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append data into csvfile and parse metadata\n",
    "counter = 0\n",
    "with open(os.path.join(output, 'metadata.csv'), 'a', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for filename in os.listdir(o_images):\n",
    "        if filename.endswith(\".meta\"):\n",
    "            name = filename.split(\".\")[0]\n",
    "            with open(os.path.join(o_images, filename), 'r') as file:\n",
    "                data = json.load(file)\n",
    "                relevant_data = [name] # add filename to the list\n",
    "                \n",
    "                for key in data.keys():\n",
    "                    relevant_data.append(data[key]) #add metadata to list\n",
    "                    \n",
    "                    label_exist = False\n",
    "                    for label in os.listdir(o_labels):\n",
    "                        if label.split(\".\")[0] == name:\n",
    "                            label_exist = True #add glottis status to list \n",
    "                            break\n",
    "                    if label_exist:\n",
    "                        relevant_data.append(\"Open\")\n",
    "                    else:\n",
    "                        relevant_data.append(\"Closed\")\n",
    "\n",
    "                if counter < lastnum: #add data type to list\n",
    "                    relevant_data.append(\"train\")\n",
    "                else:\n",
    "                    relevant_data.append(\"test\")\n",
    "                counter += 1\n",
    "                writer.writerow(relevant_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Negative Samples Annotation File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "firstly remove all .meta files and _seg.png files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all files except images \n",
    "a = 0\n",
    "for file in os.listdir(o_images):\n",
    "    if file.endswith(\".meta\"):\n",
    "        os.remove(os.path.join(o_images, file))\n",
    "        a += 1\n",
    "    if file.endswith(\"_seg.png\"):\n",
    "        os.remove(os.path.join(o_images, file))\n",
    "        a += 1\n",
    "\n",
    "if a == 118500: # total remaining files should be 55950\n",
    "    print(\"Files removed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add empty .txt files for those missing labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For fyp dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Number of missing annotations:  3964\n",
      "Number of missing annotations:  0\n",
      "Total number of images:  59250\n",
      "Total number of annotations:  59250\n"
     ]
    }
   ],
   "source": [
    "#check which files are missing\n",
    "c = 0\n",
    "for file in os.listdir(o_images):\n",
    "    name = file.split(\".\")[0]\n",
    "    if not os.path.exists(os.path.join(o_labels, name + \".txt\")):\n",
    "        c += 1\n",
    "        # print(name) \n",
    "        with open(os.path.join(o_labels, name + \".txt\"), \"w\") as f:\n",
    "            pass\n",
    "\n",
    "print(\"Initial Number of missing annotations: \", 3964)\n",
    "print(\"Number of missing annotations: \", c)\n",
    "print(\"Total number of images: \", len(os.listdir(o_images)))\n",
    "print(\"Total number of annotations: \", len(os.listdir(o_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset to train, val and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the splitting will be done on the paths of the images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images:  47400\n",
      "Number of training labels:  47400\n",
      "Number of validation images:  10665\n",
      "Number of validation labels:  10665\n",
      "Number of test images:  1185\n",
      "Number of test labels:  1185\n"
     ]
    }
   ],
   "source": [
    "#create a list of all images values\n",
    "\n",
    "images_path = sorted(os.listdir(o_images))\n",
    "labels_path = sorted(os.listdir(o_labels))\n",
    "\n",
    "#split the data into training and validation \n",
    "X_train, X_temp, y_train, y_temp = train_test_split(images_path, labels_path, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.1, random_state=42)\n",
    "\n",
    "#copy the images and labels to the respective folders\n",
    "for image in X_train:\n",
    "    shutil.copy2(os.path.join(o_images, image), train_img)\n",
    "for label in y_train:\n",
    "    shutil.copy2(os.path.join(o_labels, label), train_label)\n",
    "for image in X_val:\n",
    "    shutil.copy2(os.path.join(o_images, image), val_img)\n",
    "for label in y_val:\n",
    "    shutil.copy2(os.path.join(o_labels, label), val_label)\n",
    "for image in X_test:\n",
    "    shutil.copy2(os.path.join(o_images, image), test_img)\n",
    "for label in y_test:\n",
    "    shutil.copy2(os.path.join(o_labels, label), test_label)\n",
    "    \n",
    "print(\"Number of training images: \", len(os.listdir(train_img)))\n",
    "print(\"Number of training labels: \", len(os.listdir(train_label)))\n",
    "print(\"Number of validation images: \", len(os.listdir(val_img)))\n",
    "print(\"Number of validation labels: \", len(os.listdir(val_label)))\n",
    "print(\"Number of test images: \", len(os.listdir(test_img)))\n",
    "print(\"Number of test labels: \", len(os.listdir(test_label)))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
